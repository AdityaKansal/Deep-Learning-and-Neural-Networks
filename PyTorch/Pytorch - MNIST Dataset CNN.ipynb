{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#importing libraires\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import datasets,transforms\nfrom torch import nn\nfrom torch.nn import Linear ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\ntraining_datasets = datasets.MNIST(root='',download=True,train=True,transform=transform)\ntest_datasets = datasets.MNIST(root='',download=True,train=False,transform=transform)\ntraining_dataloader = torch.utils.data.DataLoader(dataset=training_datasets,shuffle=True,batch_size=100)\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_datasets,shuffle=True,batch_size=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def im_convert(tensor):\n    image = tensor.numpy()\n    image = image.transpose(1,2,0)\n    image = image *np.array(0.5) + np.array(0.5)\n    image = image.clip(0,1)\n    return image[:,:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_iter = iter(training_dataloader)\nimages,labels = data_iter.next()\n\nfig = plt.figure(figsize=(25,4))\n\nfor idx in np.arange(10):\n    ax = fig.add_subplot(2,10,idx+1)\n    plt.imshow(im_convert(images[idx]))\n    ax.set_title([labels[idx].item()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining CNN  - Copying Le_Net CNN model arhcitechture\nclass Le_Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.Conv1 = nn.Conv2d(in_channels=1,out_channels=20,kernel_size=5,stride=1) # for square kernel, we can give kernel size as only one number\n        self.Conv2 = nn.Conv2d(in_channels=20,out_channels=50,kernel_size=5,stride=1)\n        self.FC1 = nn.Linear(in_features=4*4*50,out_features=500)\n        self.dropout = nn.Dropout(0.5)\n        self.FC2 = nn.Linear(in_features=500,out_features=10)\n        \n        \n    def forward(self,x):\n        x = F.relu(self.Conv1(x))\n        x = F.max_pool2d(x,2,2)\n        x = F.relu(self.Conv2(x))\n        x = F.max_pool2d(x,2,2)\n        x = x.view(-1,4*4*50)\n        x = F.relu(self.FC1(x))\n        x = self.dropout(x)\n        x = self.FC2(x)\n        return x\n    \n    def predict(self,x):\n        x = F.relu(self.Conv1(x))\n        x = F.max_pool2d(x,2,2)\n        x = F.relu(self.Conv2(x))\n        x = F.max_pool2d(x,2,2)\n        x = x.view(-1,4*4*50)\n        x = F.relu(self.FC1(x))\n        x = self.FC2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Le_Net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\ntrain_losses = []\ntrain_accuracies = []\ntest_losses = []\ntest_accuracies = []\n\nfor epoch in range(epochs):\n    batch_loss = []\n    batch_accuracies = []\n    for inputs,labels in training_dataloader:\n        Y_pred = model.forward(inputs)\n        loss = criterion(Y_pred,labels)\n        batch_loss.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        #batch accuracy\n        _,pred = torch.max(Y_pred,1)\n        batch_accuracy = torch.sum(pred == labels.data).item()\n        batch_accuracies.append(batch_accuracy)\n    \n    test_batch_loss = []\n    test_batch_accuracies = []\n    for test_inputs,test_labels in test_dataloader:\n        with torch.no_grad():\n            predictions = model.predict(test_inputs)\n            test_loss = criterion(predictions,test_labels)\n            test_batch_loss.append(test_loss.item())\n            _,test_pred = torch.max(predictions,1)\n            test_batch_accuracy = torch.sum(pred == test_labels.data).item()\n            test_batch_accuracies.append(batch_accuracy)\n\n    #for training        \n    mean_epochloss = np.array(batch_loss).mean()\n    mean_epoch_accuracy = np.array(batch_accuracies).mean()\n    #for testing\n    test_mean_epochloss = np.array(test_batch_loss).mean()\n    test_mean_epoch_accuracy = np.array(test_batch_accuracies).mean()\n    print('for epoch {} ,training loss {:.4f}/accuracy {:.4f} , Test loss {:.4f}/accuracy as {:.4f}'.format(epoch,mean_epochloss,mean_epoch_accuracy,test_mean_epochloss,test_mean_epoch_accuracy))\n    train_losses.append(mean_epochloss)\n    train_accuracies.append(mean_epoch_accuracy)\n    test_losses.append(test_mean_epochloss)\n    test_accuracies.append(test_mean_epoch_accuracy)\n    #training accuracy\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss\nplt.plot(range(epochs),train_losses,label = 'train')\nplt.plot(range(epochs),test_losses,label ='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy plot\nplt.plot(range(epochs),train_accuracies,label = 'train')\nplt.plot(range(epochs),test_accuracies,label = 'test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.argmax(F.softmax(predictions),1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting images\nimport requests\nfrom PIL import Image\nfrom PIL import ImageOps\nurl = 'https://images.homedepot-static.com/productImages/007164ea-d47e-4f66-8d8c-fd9f621984a2/svn/architectural-mailboxes-house-letters-numbers-3585b-5-64_1000.jpg'\nresponse = requests.get(url,stream = True)\nimg = Image.open(response.raw)\nimg = ImageOps.invert(img)\nimg = img.convert('1')\nimg = transform(img)\nplt.imshow(im_convert(img))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = img.view(-1,1,28,28)\nprediction = model.predict(img)\n_,test_pred = torch.max(prediction,1)\nprint(test_pred.item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualising what model has learnt\nfor name,parameters in model.named_parameters():\n    if parameters.requires_grad:\n        print(name,parameters.data.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(20):\n#     plt.imshow(model.Conv1.weight[i,0].data.numpy())\n\n\n# test_no = 16   \n# grid_dim = np.int(np.sqrt(test_no))\n\n\nfig = plt.figure(figsize=(10,10))\nfor i in range(20):\n    temp = fig.add_subplot(5,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    plt.imshow(model.Conv1.weight[i,0].data.numpy())\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nfor i in range(50):\n    temp = fig.add_subplot(5,10,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    plt.imshow(model.Conv2.weight[i,0].data.numpy())\n\nfig.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.Conv2.weight.data.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#intermediate outputs\n#conv1 outout\nsample_image = training_dataloader.dataset.data[2,].numpy()\nplt.imshow(sample_image)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import signal\n#conv1 layer output\n      \nfig = plt.figure(figsize=(10,10))\n\nfor i in range(20):\n    temp = fig.add_subplot(5,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel = model.Conv1.weight[i,0].data.numpy()\n    out = signal.convolve2d(sample_image,kernel,boundary='symm',mode= 'valid')\n    plt.imshow(out)\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying relu to them\ndef ReLU(x):\n    return x * (x > 0)\n\n\nfig = plt.figure(figsize=(10,10))\n\nfor i in range(20):\n    temp = fig.add_subplot(5,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel = model.Conv1.weight[i,0].data.numpy()\n    out = signal.convolve2d(sample_image,kernel,boundary='symm',mode= 'valid')\n    out = ReLU(out)\n    plt.imshow(out)\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying max pooling\nimport skimage.measure\n\nfig = plt.figure(figsize=(10,10))\n\nfor i in range(20):\n    temp = fig.add_subplot(5,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel = model.Conv1.weight[i,0].data.numpy()\n    out = signal.convolve2d(sample_image,kernel,boundary='symm',mode= 'valid')\n    out = ReLU(out)\n    out = skimage.measure.block_reduce(out, (2,2), np.max)\n    plt.imshow(out)\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel2 = model.Conv2.weight[0,].data.numpy()\nkernel2 = kernel2.transpose(1,2,0)\nkernel2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying conv2 \nfig = plt.figure(figsize=(10,10))\n#from astropy.convolution import convolve\nimport scipy\n\nfor j in range(50): \n    temp = fig.add_subplot(10,5,j+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel2 = model.Conv2.weight[j,].data.numpy()\n    kernel2 = kernel2.transpose(1,2,0)\n    #print('shape of kernel',kernel2.shape)\n    arr = []\n    for i in range(20):\n        kernel = model.Conv1.weight[i,0].data.numpy()\n        out = signal.convolve2d(sample_image,kernel,boundary='symm',mode= 'valid')\n        out = ReLU(out)\n        out = skimage.measure.block_reduce(out, (2,2), np.max)\n        arr.append(out)\n\n    arr = np.array(arr)\n    arr = arr.transpose(1,2,0)\n    #print('input shape',arr.shape)\n    out2= scipy.signal.convolve(arr,kernel2,mode = 'valid')\n    plt.imshow(out2[:,:,0])\n\nfig.show() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#relu again\nfig = plt.figure(figsize=(10,10))\n#from astropy.convolution import convolve\nimport scipy\n\nfor j in range(50): \n    temp = fig.add_subplot(10,5,j+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel2 = model.Conv2.weight[j,].data.numpy()\n    kernel2 = kernel2.transpose(1,2,0)\n    #print('shape of kernel',kernel2.shape)\n    arr = []\n    for i in range(20):\n        kernel = model.Conv1.weight[i,0].data.numpy()\n        out = signal.convolve2d(sample_image,kernel,boundary='symm',mode= 'valid')\n        out = ReLU(out)\n        out = skimage.measure.block_reduce(out, (2,2), np.max)\n        arr.append(out)\n\n    arr = np.array(arr)\n    arr = arr.transpose(1,2,0)\n    #print('input shape',arr.shape)\n    out2= scipy.signal.convolve(arr,kernel2,mode = 'valid')\n    out2 = ReLU(out2)\n    plt.imshow(out2[:,:,0])\n\nfig.show() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(range(20))\ny = np.sin(6*x)\nplt.plot(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LeNet model on CIFAR10 Dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#importing libraires\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import datasets,transforms\nfrom torch import nn\nfrom torch.nn import Linear ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\ntraining_datasets = datasets.CIFAR10(root='./data',download=True,train=True,transform=transform)\ntest_datasets = datasets.CIFAR10(root='./data',download=True,train=False,transform=transform)\ntraining_dataloader = torch.utils.data.DataLoader(dataset=training_datasets,shuffle=True,batch_size=100)\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_datasets,shuffle=True,batch_size=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def im_convert(tensor):\n    image = tensor.numpy()\n    image = image.transpose(1,2,0)\n    image = image *np.array(0.5) + np.array(0.5)\n    image = image.clip(0,1)\n    #image = np.fliplr(image.reshape(-1,3)).reshape(image.shape)\n    #print(image.shape)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline \ndata_iter = iter(training_dataloader)\nimages,labels = data_iter.next()\n\nfig = plt.figure(figsize=(25,4))\n\nfor idx in np.arange(10):\n    ax = fig.add_subplot(2,10,idx+1)\n    im = im_convert(images[idx])\n    plt.imshow(im_convert(images[idx]))\n    ax.set_title([classes[labels[idx].item()]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining CNN  - Copying Le_Net CNN model arhcitechture\nclass Le_Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.Conv1 = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=1) # for square kernel, we can give kernel size as only one number\n        self.Conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n        self.Conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n        self.FC1 = nn.Linear(in_features=4*4*64,out_features=500)\n        self.dropout = nn.Dropout(0.5)\n        self.FC2 = nn.Linear(in_features=500,out_features=10)\n        \n        \n    def forward(self,x):\n        x = F.relu(self.Conv1(x))\n        x = F.max_pool2d(x,2,2)\n        x = F.relu(self.Conv2(x))\n        x = F.max_pool2d(x,2,2)\n        x = F.relu(self.Conv3(x))\n        x = F.max_pool2d(x,2,2)\n        x = x.view(-1,4*4*64)\n        x = F.relu(self.FC1(x))\n        x = self.dropout(x)\n        x = self.FC2(x)\n        return x\n    \n    def predict(self,x):\n        x = F.relu(self.Conv1(x))\n        x = F.max_pool2d(x,2,2)\n        x = F.relu(self.Conv2(x))\n        x = F.max_pool2d(x,2,2)\n        x = F.relu(self.Conv3(x))\n        x = F.max_pool2d(x,2,2)\n        x = x.view(-1,4*4*64)\n        x = F.relu(self.FC1(x))\n        x = self.FC2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Le_Net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\ntrain_losses = []\ntrain_accuracies = []\ntest_losses = []\ntest_accuracies = []\n\nfor epoch in range(epochs):\n    batch_loss = []\n    batch_accuracies = []\n    for inputs,labels in training_dataloader:\n        Y_pred = model.forward(inputs)\n        loss = criterion(Y_pred,labels)\n        batch_loss.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        #batch accuracy\n        _,pred = torch.max(Y_pred,1)\n        batch_accuracy = torch.sum(pred == labels.data).item()\n        batch_accuracies.append(batch_accuracy)\n    \n    test_batch_loss = []\n    test_batch_accuracies = []\n    for test_inputs,test_labels in test_dataloader:\n        with torch.no_grad():\n            predictions = model.predict(test_inputs)\n            test_loss = criterion(predictions,test_labels)\n            test_batch_loss.append(test_loss.item())\n            _,test_pred = torch.max(predictions,1)\n            test_batch_accuracy = torch.sum(pred == test_labels.data).item()\n            test_batch_accuracies.append(batch_accuracy)\n\n    #for training        \n    mean_epochloss = np.array(batch_loss).mean()\n    mean_epoch_accuracy = np.array(batch_accuracies).mean()\n    #for testing\n    test_mean_epochloss = np.array(test_batch_loss).mean()\n    test_mean_epoch_accuracy = np.array(test_batch_accuracies).mean()\n    print('for epoch {} ,training loss {:.4f}/accuracy {:.4f} , Test loss {:.4f}/accuracy as {:.4f}'.format(epoch+1,mean_epochloss,mean_epoch_accuracy,test_mean_epochloss,test_mean_epoch_accuracy))\n    train_losses.append(mean_epochloss)\n    train_accuracies.append(mean_epoch_accuracy)\n    test_losses.append(test_mean_epochloss)\n    test_accuracies.append(test_mean_epoch_accuracy)\n    #training accuracy\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss\nplt.plot(range(epochs),train_losses,label = 'train')\nplt.plot(range(epochs),test_losses,label ='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy plot\nplt.plot(range(epochs),train_accuracies,label = 'train')\nplt.plot(range(epochs),test_accuracies,label = 'test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.argmax(F.softmax(predictions),1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting images\nimport requests\nfrom PIL import Image\nfrom PIL import ImageOps\nurl = 'https://images.unsplash.com/photo-1518791841217-8f162f1e1131?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&w=1000&q=80'\nresponse = requests.get(url,stream = True)\nimg = Image.open(response.raw)\n#img = ImageOps.invert(img)\n#img = img.convert('1')\nimg = transform(img)\nprint(img.shape)\nplt.imshow(im_convert(img))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = img.view(-1,3,32,32)\nprediction = model.predict(img)\n_,test_pred = torch.max(prediction,1)\nprint(classes[test_pred.item()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualising what model has learnt\nfor name,parameters in model.named_parameters():\n    if parameters.requires_grad:\n        print(name,parameters.data.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(20):\n#     plt.imshow(model.Conv1.weight[i,0].data.numpy())\n\n\n# test_no = 16   \n# grid_dim = np.int(np.sqrt(test_no))\n\n\nfig = plt.figure(figsize=(10,10))\nfor i in range(16):\n    temp = fig.add_subplot(4,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    plt.imshow(model.Conv1.weight[i,].data.numpy())\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nfor i in range(32):\n    temp = fig.add_subplot(8,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    img = model.Conv2.weight[i,].data.numpy()\n    plt.imshow(img)\n\nfig.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nfor i in range(64):\n    temp = fig.add_subplot(8,8,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    img = model.Conv3.weight[i,].data.numpy()\n    plt.imshow(img)\n\nfig.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.Conv2.weight.data.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#intermediate outputs\n#conv1 outout\nsample_image = training_dataloader.dataset.data[12,]\nplt.imshow(sample_image)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import signal\n#conv1 layer output\n      \nfig = plt.figure(figsize=(10,10))\n\nfor i in range(16):\n    temp = fig.add_subplot(4,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel = model.Conv1.weight[i,].data.numpy()\n    #print(kernel.shape)\n    #print(sample_image.shape)\n    out = signal.convolve(sample_image,kernel,mode = 'valid')\n    #print(out.shape)\n    plt.imshow(out[:,:,0])\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom scipy import signal\n#relu\n#applying relu to them\ndef ReLU(x):\n    return x * (x > 0)\n     \nfig = plt.figure(figsize=(10,10))\n\nfor i in range(16):\n    temp = fig.add_subplot(4,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel = model.Conv1.weight[i,].data.numpy()\n    #print(kernel.shape)\n    #print(sample_image.shape)\n    out = signal.convolve(sample_image,kernel,mode = 'valid')\n    #print(out.shape)\n    out = ReLU(out)\n    plt.imshow(out[:,:,0])\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying max pooling\nimport skimage.measure\n\nfrom scipy import signal\n#relu\n#applying relu to them\ndef ReLU(x):\n    return x * (x > 0)\n     \nfig = plt.figure(figsize=(10,10))\n\nfor i in range(16):\n    temp = fig.add_subplot(4,4,i+1)\n    temp.set_xticks([])\n    temp.set_yticks([])\n    kernel = model.Conv1.weight[i,].data.numpy()\n    #print(kernel.shape)\n    #print(sample_image.shape)\n    out = signal.convolve(sample_image,kernel,mode = 'valid')\n    #print(out.shape)\n    out = ReLU(out)\n    #print(out.shape)\n    out = skimage.measure.block_reduce(out[:,:,0], (2,2), np.max)\n    #print(out.shape)\n    plt.imshow(out)\n\nfig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel2 = model.Conv2.weight[0,].data.numpy()\nkernel2 = kernel2.transpose(1,2,0)\nkernel2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying conv2 \n#fig = plt.figure(figsize=(10,10))\nfrom astropy.convolution import convolve\nimport scipy\n\nfor j in range(50): \n    kernel2 = model.Conv2.weight[j,].data.numpy()\n    print('shape of kernel',kernel2.shape)\n    arr = []\n    for i in range(20):\n        kernel = model.Conv1.weight[i,0].data.numpy()\n        out = signal.convolve2d(sample_image,kernel,boundary='symm',mode= 'valid')\n        out = ReLU(out)\n        out = skimage.measure.block_reduce(out, (2,2), np.max)\n        arr.append(out)\n\n    arr = np.array(arr)\n    print('array shape',arr.shape)\n#     arr = arr.transpose(1,2,0)\n#     kernel2 = kernel2.transpose(1,2,0)\n    out2= scipy.ndimage.convolve(out,kernel2,'same')\n    print('out2 shape',out2.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(range(20))\ny = np.sin(6*x)\nplt.plot(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Pretrained Models"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#importing libraires\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import datasets,transforms,models\nfrom torch import nn\nfrom torch.nn import Linear ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\ntraining_datasets = datasets.CIFAR10(root='./data',download=True,train=True,transform=transform)\ntest_datasets = datasets.CIFAR10(root='./data',download=True,train=False,transform=transform)\ntraining_dataloader = torch.utils.data.DataLoader(dataset=training_datasets,shuffle=True,batch_size=100)\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_datasets,shuffle=True,batch_size=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def im_convert(tensor):\n    image = tensor.numpy()\n    image = image.transpose(1,2,0)\n    image = image *np.array(0.5) + np.array(0.5)\n    image = image.clip(0,1)\n    #image = np.fliplr(image.reshape(-1,3)).reshape(image.shape)\n    #print(image.shape)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline \ndata_iter = iter(training_dataloader)\nimages,labels = data_iter.next()\n\nfig = plt.figure(figsize=(25,4))\n\nfor idx in np.arange(10):\n    ax = fig.add_subplot(2,10,idx+1)\n    im = im_convert(images[idx])\n    plt.imshow(im_convert(images[idx]))\n    ax.set_title([classes[labels[idx].item()]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Defining CNN  - Copying Le_Net CNN model arhcitechture\n# class Le_Net(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.Conv1 = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=1) # for square kernel, we can give kernel size as only one number\n#         self.Conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n#         self.Conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n#         self.FC1 = nn.Linear(in_features=4*4*64,out_features=500)\n#         self.dropout = nn.Dropout(0.5)\n#         self.FC2 = nn.Linear(in_features=500,out_features=10)\n        \n        \n#     def forward(self,x):\n#         x = F.relu(self.Conv1(x))\n#         x = F.max_pool2d(x,2,2)\n#         x = F.relu(self.Conv2(x))\n#         x = F.max_pool2d(x,2,2)\n#         x = F.relu(self.Conv3(x))\n#         x = F.max_pool2d(x,2,2)\n#         x = x.view(-1,4*4*64)\n#         x = F.relu(self.FC1(x))\n#         x = self.dropout(x)\n#         x = self.FC2(x)\n#         return x\n    \n#     def predict(self,x):\n#         x = F.relu(self.Conv1(x))\n#         x = F.max_pool2d(x,2,2)\n#         x = F.relu(self.Conv2(x))\n#         x = F.max_pool2d(x,2,2)\n#         x = F.relu(self.Conv3(x))\n#         x = F.max_pool2d(x,2,2)\n#         x = x.view(-1,4*4*64)\n#         x = F.relu(self.FC1(x))\n#         x = self.FC2(x)\n#         return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.vgg16(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for params in model.features.parameters():\n    params.requires_grad = False\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_input = model.classifier[6].in_features\nlast_layer = nn.Linear(in_features = n_input,out_features=10)\nmodel.classifier[6] = last_layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5\ntrain_losses = []\ntrain_accuracies = []\ntest_losses = []\ntest_accuracies = []\n\nfor epoch in range(epochs):\n    batch_loss = []\n    batch_accuracies = []\n    for inputs,labels in training_dataloader:\n        Y_pred = model.forward(inputs)\n        loss = criterion(Y_pred,labels)\n        batch_loss.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        #batch accuracy\n        _,pred = torch.max(Y_pred,1)\n        batch_accuracy = torch.sum(pred == labels.data).item()\n        batch_accuracies.append(batch_accuracy)\n    \n    test_batch_loss = []\n    test_batch_accuracies = []\n    for test_inputs,test_labels in test_dataloader:\n        with torch.no_grad():\n            predictions = model.predict(test_inputs)\n            test_loss = criterion(predictions,test_labels)\n            test_batch_loss.append(test_loss.item())\n            _,test_pred = torch.max(predictions,1)\n            test_batch_accuracy = torch.sum(pred == test_labels.data).item()\n            test_batch_accuracies.append(batch_accuracy)\n\n    #for training        \n    mean_epochloss = np.array(batch_loss).mean()\n    mean_epoch_accuracy = np.array(batch_accuracies).mean()\n    #for testing\n    test_mean_epochloss = np.array(test_batch_loss).mean()\n    test_mean_epoch_accuracy = np.array(test_batch_accuracies).mean()\n    print('for epoch {} ,training loss {:.4f}/accuracy {:.4f} , Test loss {:.4f}/accuracy as {:.4f}'.format(epoch+1,mean_epochloss,mean_epoch_accuracy,test_mean_epochloss,test_mean_epoch_accuracy))\n    train_losses.append(mean_epochloss)\n    train_accuracies.append(mean_epoch_accuracy)\n    test_losses.append(test_mean_epochloss)\n    test_accuracies.append(test_mean_epoch_accuracy)\n    #training accuracy\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss\nplt.plot(range(epochs),train_losses,label = 'train')\nplt.plot(range(epochs),test_losses,label ='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy plot\nplt.plot(range(epochs),train_accuracies,label = 'train')\nplt.plot(range(epochs),test_accuracies,label = 'test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}