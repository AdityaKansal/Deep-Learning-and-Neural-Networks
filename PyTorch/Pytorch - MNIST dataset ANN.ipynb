{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### ANN for MNIST dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraires\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets,transforms\nfrom torch import nn\nfrom torch.nn import Linear ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\ntraining_datasets = datasets.MNIST(root='',download=True,train=True,transform=transform)\ntest_datasets = datasets.MNIST(root='',download=True,train=False,transform=transform)\ntraining_dataloader = torch.utils.data.DataLoader(dataset=training_datasets,shuffle=True,batch_size=100)\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_datasets,shuffle=True,batch_size=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def im_convert(tensor):\n    image = tensor.numpy()\n    image = image.transpose(1,2,0)\n    image = image *np.array(0.5) + np.array(0.5)\n    image = image.clip(0,1)\n    return image[:,:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_iter = iter(training_dataloader)\nimages,labels = data_iter.next()\n\nfig = plt.figure(figsize=(25,4))\n\nfor idx in np.arange(10):\n    ax = fig.add_subplot(2,10,idx+1)\n    plt.imshow(im_convert(images[idx]))\n    ax.set_title([labels[idx].item()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining ANN\nclass Classifier(nn.Module):\n    def __init__(self,input_size,H1,H2,H3,output_size):\n        super().__init__()\n        self.linear1 = Linear(input_size,H1)\n        self.linear2 = Linear(H1,H2)\n        self.linear3 = Linear(H2,H3)\n        self.linear4 = Linear(H3,output_size)\n        \n    def forward(self,x):\n        x = torch.relu(self.linear1(x))\n        x = torch.relu(self.linear2(x))\n        x = torch.relu(self.linear3(x))\n        x = self.linear4(x)\n        return x\n    def predict(self,x):\n        x = torch.relu(self.linear1(x))\n        x = torch.relu(self.linear2(x))\n        x = torch.relu(self.linear3(x))\n        x = self.linear4(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Classifier(784,512,256,64,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 12\ntrain_losses = []\ntrain_accuracy = []\n\nfor epoch in range(epochs):\n    batch_loss = []\n    batch_accuracies = []\n    for inputs,labels in training_dataloader:\n        inputs = inputs.view(inputs.shape[0],-1)\n        Y_pred = model.forward(inputs)\n        loss = criterion(Y_pred,labels)\n        batch_loss.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        #batch accuracy\n        _,pred = torch.max(Y_pred,1)\n        batch_accuracy = torch.sum(pred == labels.data).item()\n        batch_accuracies.append(batch_accuracy)\n    \n    test_batch_loss = []\n    test_batch_accuracies = []\n    for test_inputs,test_labels in test_dataloader:\n        test_inputs = test_inputs.view(test_inputs.shape[0],-1)\n        predictions = model.predict(test_inputs)\n        test_loss = criterion(predictions,test_labels)\n        test_batch_loss.append(test_loss.item())\n        _,test_pred = torch.max(predictions,1)\n        test_batch_accuracy = torch.sum(pred == test_labels.data).item()\n        test_batch_accuracies.append(batch_accuracy)\n        \n    #for training        \n    mean_epochloss = np.array(batch_loss).mean()\n    mean_epoch_accuracy = np.array(batch_accuracies).mean()\n    #for testing\n    test_mean_epochloss = np.array(test_batch_loss).mean()\n    test_mean_epoch_accuracy = np.array(test_batch_accuracies).mean()\n    print('for epoch {} ,training loss {:.2f}/accuracy {:.2f} , Test loss {:.2f}/accuracy as {:.2f}'.format(epoch,mean_epochloss,mean_epoch_accuracy,test_mean_epochloss,test_mean_epoch_accuracy))\n    train_losses.append(mean_epochloss)\n    train_accuracy.append(mean_epoch_accuracy)\n    \n    #training accuracy\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss\nplt.plot(range(epochs),train_losses)\n#plt.plot(range(epochs),test_mean_epochloss)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting images\nimport requests\nfrom PIL import Image\nfrom PIL import ImageOps\nurl = 'https://images.homedepot-static.com/productImages/007164ea-d47e-4f66-8d8c-fd9f621984a2/svn/architectural-mailboxes-house-letters-numbers-3585b-5-64_1000.jpg'\nresponse = requests.get(url,stream = True)\nimg = Image.open(response.raw)\nimg = ImageOps.invert(img)\nimg = img.convert('1')\nimg = transform(img)\nplt.imshow(im_convert(img))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input = img.view(img.shape[0],-1)\nprediction = model.predict(test_input)\n_,test_pred = torch.max(prediction,1)\nprint(test_pred.item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}