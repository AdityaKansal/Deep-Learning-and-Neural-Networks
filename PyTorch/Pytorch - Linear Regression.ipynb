{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = torch.tensor([2.0],requires_grad=True)\nb = torch.tensor([3.0],requires_grad=True)\nw1 = torch.tensor([1.0],requires_grad=True)\nw2 = torch.tensor([1.0],requires_grad=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = a*w1\nc.retain_grad()\nd = b*w2*w2\nd.retain_grad()\ne = c+d\ne.retain_grad()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e.backward()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(e.grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = torch.randn(1,2,requires_grad=True)\nb = torch.randn(2,1,requires_grad=True)\nc = torch.matmul(a,b)\nc.backward(retain_graph=True)\nprint(a.grad)\na.grad.zero_()\nprint(a.grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression from Scratch using Pytorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating dataset\nX = torch.randn(100,1)*10\nY = X + 3*torch.randn(100,1) +2\nplt.scatter(X.numpy(),Y.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialiation of weight and bias\nw = torch.tensor(1.0,requires_grad=True)\nb = torch.tensor(1.0,requires_grad=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_feed(x):\n    y = w*x +b\n    return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = forward_feed(X)\nloss = torch.sum((Y - Y_pred)**2)\nloss.backward()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(w.grad.item())\nw.grad.zero_()\nprint(w.grad.item())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialiation of weight and bias\nw = torch.tensor(1.0,requires_grad=True)\nb = torch.tensor(1.0,requires_grad=True)\n\n#forward pass\ndef forward_feed(x):\n    y = w*x +b\n    return y\n\nepochs = 1000\nlr = 0.00008\nloss_list = []\nfor epoch in range(epochs):\n    print('w',w)\n    print('b',b)\n    print('epoch',epoch)\n    Y_pred = forward_feed(X)\n    loss = torch.sum((Y - Y_pred)**2)\n    loss_list.append(loss)\n    print('loss ',loss)\n    loss.backward()\n    \n#     print('w.grad',w.grad)\n#     print('w.grad',b.grad)\n#     print(loss_list)\n#     print(w.grad)\n#     print(b.grad)\n    #weights updates\n#     print(lr*w.grad.item())\n#     print(lr*b.grad.item())\n    with torch.no_grad():\n        w =w- lr*w.grad\n        b =b- lr*b.grad\n        print('w',w)\n        print('b',b)\n    #     print(w,b)\n    #     print(w.grad.item())\n    #     print(b.grad.item())\n    #     w_grad = w.grad.item()\n    #     b_grad = b.grad.item()\n        w.grad.zero_()\n        b.grad.zero_()\n#         print(w.grad)\n#         print(b.grad)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MSE Loss\nplt.plot(range(epochs),loss_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#grads\n\nprint(w.item())\nprint(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = X*w.item() +b.item()\nplt.plot(X.numpy(),pred.numpy())\nplt.scatter(X.numpy(),Y.numpy())\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = torch.tensor([[1],[2],[3]])\nt1= a.expand(3,3)\nt2 = a.t().expand(3,3)\nprint('t1')\nprint(t1)\nprint('t2')\nprint(t2)\nprint('t1+t2')\nprint(t1+t2)\nt1 +=t2\nprint('t1+=t2')\nprint(t1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression using Linear Module"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear model\nfrom torch.nn import Linear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(1)\nmodel = Linear(in_features=1,out_features=1)\nprint(model.weight,model.bias)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = torch.tensor([[2.0],[3.3]])\nprint(model(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"class LR(nn.Module):\n    def __init__(self,input_size,output_size):\n        super().__init__()\n        self.linear = nn.Linear(input_size,output_size)\n        \n    def forward(self,x):\n        pred = self.linear(x)\n        return pred\n\nmodel = LR(1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(),lr= 0.0001)\nepochs = 100\nlosses = []\nfor epoch in range(epochs):\n    Y_pred = model.forward(X)\n    loss = criterion(Y_pred,Y)\n    losses.append(loss)\n    print('epoch ',epoch, ' loss :',loss.item())\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(1)\nmodel = LR(1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x = torch.tensor([[1.0],[2.0]])\nprint(model.forward(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_params(model):\n    w,b =model.parameters()\n    return w[0][0].item(),b[0].item()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w1,b1 = get_params(model)\nprint(w1,b1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = X*w1 +b1\nplt.plot(X.numpy(),pred.numpy())\nplt.scatter(X.numpy(),Y.numpy())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Linear Regression using direct Linear class of Pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inputs\n#creating dataset\nX = torch.randn(100,1)*10\nY = X + 3*torch.randn(100,1) +2\nplt.scatter(X.numpy(),Y.numpy())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.nn.modules import Linear\n\nmodel = Linear(1,1)\noptimizer = torch.optim.SGD(model.parameters(),lr = 0.001)\ncriterion = torch.nn.MSELoss()\nfor epoch in range(100):\n    Y_pred = model(X)\n    loss = criterion(Y_pred,Y)\n    #print('epoch ',epoch,' loss ',loss )\n    w,b = model.parameters()\n    print(w.grad,b.grad)\n    #optimizer.zero_grad()\n    loss.backward()\n    print(w.grad,b.grad)\n    optimizer.step()\n    w.grad.zero_()\n    b.grad.zero_()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w,b =model.parameters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}